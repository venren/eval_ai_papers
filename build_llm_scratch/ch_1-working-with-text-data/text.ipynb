{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36e8670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_verdict_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b334ffc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 'The Verdict' short story...\n",
      "  Trying: https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\n",
      "  ✓ Success!\n",
      "✓ Saved to the_verdict.txt (20479 characters)\n"
     ]
    }
   ],
   "source": [
    "raw_text = get_verdict_story(force_download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c91058",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./the_verdict.txt\",\"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4221ea5",
   "metadata": {},
   "source": [
    "### Naive implementation\n",
    "1. Split raw_text in to tokens\n",
    "2. Create dict of words to token id. (this is buidl vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59a9b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text_tokens(input_text: str) -> list:\n",
    "    # Pattern: match words or punctuation, skip whitespace\n",
    "    pattern = r'\\b\\w+\\b|[^\\w\\s]'\n",
    "    tokens = re.findall(pattern, input_text)\n",
    "    return tokens\n",
    "\n",
    "def create_vocabulary(tokens) -> dict:\n",
    "    tokens.sort()\n",
    "    unique_tokens = set(tokens)\n",
    "    vocab = {token:integer for integer, token in enumerate(unique_tokens)}\n",
    "    return vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af035c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 200 chars: I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a\n",
      "\n",
      "Tokens: ['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '-', '-', 'though', 'a', 'good', 'fellow', 'enough', '-', '-', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that']\n",
      "Total tokens: 4827\n",
      "\n",
      "Vocabulary size: 1148\n",
      "Gisburn token ID: 105\n",
      "Gisburn token ID: 422\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "tokens = split_text_tokens(raw_text)\n",
    "print(f\"First 200 chars: {raw_text[:200]}\")\n",
    "print(f\"\\nTokens: {tokens[:30]}\")\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "\n",
    "vocab = create_vocabulary(tokens)\n",
    "print(f\"\\nVocabulary size: {len(vocab)}\")\n",
    "print(f\"Gisburn token ID: {vocab['Gisburn']}\")\n",
    "print(f\"Gisburn token ID: {vocab['genius']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fe97e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad0f3c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You monumental Lord!!!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "token_ids = tokenizer.encode(\"You monumental Lord!!!\")\n",
    "result = tokenizer.decode(token_ids)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Build LLM Scratch",
   "language": "python",
   "name": "build_llm_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
